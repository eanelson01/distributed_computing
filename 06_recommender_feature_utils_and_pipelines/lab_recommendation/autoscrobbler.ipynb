{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Music Recommendation\n",
    "### University of Virginia\n",
    "### DS 7200: Distributed Computing\n",
    "### Last Updated: August 20, 2023\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Instructions\n",
    "\n",
    "In this assignment, you will prepare data and build an ALS recommendation algorithm based on user listening data from Autoscrobbler.\n",
    "\n",
    "The data consists of: \n",
    "- user data (listeners)\n",
    "- item data (songs)\n",
    "- interaction data (user listens, which is implicit feedback).  \n",
    "\n",
    "The code is outlined below. Make the requested modifications, run the code, and copy all answers to the **ANSWER SECTION** at the bottom of the notebook. Note the *None* variable is a placeholder for code.\n",
    "\n",
    "**NOTE**: For a given userID, some/many recommendation might come back as $None$.  \n",
    "This comes from artists not used in the training data.  \n",
    "These should be filtered out using a list comprehension as follows:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`print([x for x in recommendationsForUser if x is not None])`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TOTAL POINTS: 10**\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import modules\n",
    "import os\n",
    "\n",
    "from pyspark import SparkContext\n",
    "from pyspark import SparkConf\n",
    "from pyspark.mllib import recommendation\n",
    "from pyspark.mllib.recommendation import *\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# set configurations\n",
    "conf = SparkConf().setMaster(\"local\").setAppName(\"autoscrobbler\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/pyspark/bin/load-spark-env.sh: line 68: ps: command not found\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/10/18 18:37:30 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "# set context\n",
    "sc = SparkContext.getOrCreate(conf=conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# pathing and params\n",
    "user_artist_data_file = '/standard/ds7200-apt4c/large_datasets/user_artist_data.txt'\n",
    "artist_data_file = 'artist_data.txt'\n",
    "artist_alias_data_file  = 'artist_alias.txt'\n",
    "\n",
    "numPartitions = 2\n",
    "topk = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "/standard/ds7200-apt4c/large_datasets/user_artist_data.txt MapPartitionsRDD[1] at textFile at NativeMethodAccessorImpl.java:0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read user_artist_data_file into RDD (417MB file, 24MM records of users’ plays of artists, along with count)\n",
    "# specifically, each row holds: userID, artistID, count\n",
    "rawDataRDD = sc.textFile(user_artist_data_file, numPartitions)\n",
    "rawDataRDD.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 0:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/10/18 18:37:37 WARN BlockManager: Task 0 already completed, not releasing lock for rdd_1_0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['1000002 1 55', '1000002 1000006 33']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# inspect some records\n",
    "rawDataRDD.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "artist_data.txt MapPartitionsRDD[4] at textFile at NativeMethodAccessorImpl.java:0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read artist_data_file using *textFile*\n",
    "rawArtistRDD = sc.textFile(artist_data_file, numPartitions)\n",
    "rawArtistRDD.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/10/18 18:37:37 WARN BlockManager: Task 1 already completed, not releasing lock for rdd_4_0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['1134999\\t06Crazy Life', '6821360\\tPang Nakarin']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# inspect some records\n",
    "rawArtistRDD.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# read artist_alias_data_file using *textFile*\n",
    "artist_allias_rdd = sc.textFile(artist_alias_data_file, numPartitions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1092764\\t1000311', '1095122\\t1000557']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# inspect some records\n",
    "artist_allias_rdd.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1092764\\t1000311',\n",
       " '1095122\\t1000557',\n",
       " '6708070\\t1007267',\n",
       " '10088054\\t1042317',\n",
       " '1195917\\t1042317',\n",
       " '1112006\\t1000557',\n",
       " '1187350\\t1294511',\n",
       " '1116694\\t1327092',\n",
       " '6793225\\t1042317',\n",
       " '1079959\\t1000557']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1) (1 PT) Print the first 10 records from rawDataRDD\n",
    "artist_allias_rdd.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) (1 PT) Apply parseArtistIdNamePair to rawArtistRDD, and print the first 10 records, showing only artist names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def parseArtistIdNamePair(singlePair):\n",
    "   splitPair = singlePair.rsplit('\\t')\n",
    "   # we should have two items in the list - id and name of the artist.\n",
    "   if len(splitPair) != 2:\n",
    "       #print singlePair\n",
    "       return []\n",
    "   else:\n",
    "       try:\n",
    "           return [(int(splitPair[0]), splitPair[1])]\n",
    "       except:\n",
    "           return []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['06Crazy Life',\n",
       " 'Pang Nakarin',\n",
       " 'Terfel, Bartoli- Mozart: Don',\n",
       " 'The Flaming Sidebur',\n",
       " 'Bodenstandig 3000',\n",
       " 'Jota Quest e Ivete Sangalo',\n",
       " 'Toto_XX (1977',\n",
       " 'U.S Bombs -',\n",
       " 'artist formaly know as Mat',\n",
       " 'Kassierer - Musik für beide Ohren']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# do the flatmapping to the RDD using the function and collect, then print the values\n",
    "artistByID = dict(rawArtistRDD.flatMap(lambda x: parseArtistIdNamePair(x)).collect())\n",
    "artist_vals = artistByID.values()\n",
    "list(artist_vals)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def parseArtistAlias(alias):\n",
    "    splitPair = alias.rsplit('\\t')\n",
    "    # we should have two ids in the list.\n",
    "    if len(splitPair) != 2:\n",
    "        #print singlePair\n",
    "        return []\n",
    "    else:\n",
    "        try:\n",
    "            return [(int(splitPair[0]), int(splitPair[1]))]\n",
    "        except:\n",
    "            return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "artistAlias = artist_allias_rdd.flatMap(lambda x: parseArtistAlias(x)).collectAsMap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# turn the artistAlias into a broadcast variable.\n",
    "# This will distribute it to worker nodes efficiently, so we save bandwidth.\n",
    "artistAliasBroadcast = sc.broadcast( artistAlias )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1007797"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "artistAliasBroadcast.value.get(2097174)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 6:====================================================>    (12 + 1) / 13]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24296858\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Print the number of records from the largest RDD, rawDataRDD\n",
    "print( rawDataRDD.count() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PythonRDD[13] at RDD at PythonRDD.scala:53"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sample 10% of rawDataRDD (to reduce runtime) using seed 314. Call it sample.\n",
    "seed = 314\n",
    "weights = [0.1, 0.9]\n",
    "sample, _ = rawDataRDD.randomSplit(weights, seed)\n",
    "sample.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2429895"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/10/18 18:38:43 WARN BlockManager: Task 34 already completed, not releasing lock for rdd_13_0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['1000002 1000014 42',\n",
       " '1000002 1000088 157',\n",
       " '1000002 1000139 56',\n",
       " '1000002 1000140 95',\n",
       " '1000002 1000210 23']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# take the first 5 records from the sample. each row represents userID, artistID, count.\n",
    "sample.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Based on sampled data, build the matrix for model training\n",
    "def mapSingleObservation(x):\n",
    "    # Returns Rating object represented as (user, product, rating) tuple.\n",
    "    \n",
    "    # [add line of code here to split each record into userID, artistID, count]\n",
    "    userID, artistID, count = x.split(' ')\n",
    "\n",
    "    \n",
    "    # given possible aliasing, get finalArtistID\n",
    "    finalArtistID = artistAliasBroadcast.value.get(artistID)\n",
    "    if finalArtistID is None:\n",
    "        finalArtistID = artistID\n",
    "    return Rating(userID, finalArtistID, count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PythonRDD[16] at RDD at PythonRDD.scala:53"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainData = sample.map(lambda x: mapSingleObservation(x))\n",
    "trainData.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Rating(user=1000002, product=1000014, rating=42.0),\n",
       " Rating(user=1000002, product=1000088, rating=157.0),\n",
       " Rating(user=1000002, product=1000139, rating=56.0),\n",
       " Rating(user=1000002, product=1000140, rating=95.0),\n",
       " Rating(user=1000002, product=1000210, rating=23.0)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3) (1 PT) Print the first 5 records from trainData\n",
    "trainData.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Train the ALS implicit model (since the measurements are activity and not ratings)\n",
    "# using seed 314, rank 10, iterations 5, alpha 0.01\n",
    "model = ALS.trainImplicit(trainData, rank=10, iterations=5, alpha=0.01, seed = 314)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Model Evaluation\n",
    "\n",
    "# fetch artists for a test user\n",
    "testUserID = 1000002\n",
    "\n",
    "# broadcast artistByID for speed\n",
    "artistByIDBroadcast = sc.broadcast( artistByID )\n",
    "\n",
    "# from trainData, collect the artists for the test user. Call the object artistsForUser.\n",
    "# hint: you will need to apply .value.get(x.product) to the broadcast artistByID, where x is the Rating RDD.\n",
    "# if you don't do this, you may see artistIDs. you want artist names.\n",
    "artistsForUser = (trainData\n",
    "                  .filter(lambda observation: observation.user == testUserID)\n",
    "                  .map(lambda observation: artistByIDBroadcast.value.get(observation.product))\n",
    "                  .collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Café Del Mar', 'Eric Clapton', 'Eurythmics']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4) (1 PT) Print the artist listens for testUserID = 1000002\n",
    "[x for x in artistsForUser if x is not None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Eric Clapton', 'Dark Tranquillity', '植松伸夫', 'Scorpions', 'Enigma', 'Gary Jules', 'Eurythmics', 'Elvis Costello', 'Saliva', 'Nena']\n"
     ]
    }
   ],
   "source": [
    "# 5) (2 PTS) Make 10 recommendations for testUserID = 1000002\n",
    "num_recomm = 600 # this filters down to 10 after filtering Nones\n",
    "recommendationsForUser = map(lambda observation: artistByID.get(observation.product), model.call(\"recommendProducts\", testUserID, num_recomm))\n",
    "\n",
    "print([x for x in recommendationsForUser if x is not None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Train a second ALS model with seed 314, rank 20, iterations 5, lambda 0.01.\n",
    "m2 = ALS.trainImplicit(trainData, rank=20, iterations=5, alpha=0.01, seed = 314, lambda_ = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Eric Clapton', 'Dark Tranquillity', 'Scorpions', 'Enigma', 'Eurythmics', '植松伸夫', 'Gary Jules', 'Hypocrisy', 'Elvis Costello', 'Nena']\n"
     ]
    }
   ],
   "source": [
    "# 6) (2 PTS) Using the rank 20 model, make 10 recommendations for the same test user\n",
    "recommendationsForUser_rank20 = map(lambda observation: artistByID.get(observation.product), m2.call(\"recommendProducts\", testUserID, num_recomm))\n",
    "print([x for x in recommendationsForUser_rank20 if x is not None][:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ANSWER SECTION (COPY ALL ANSWERS HERE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1092764\\t1000311',\n",
       " '1095122\\t1000557',\n",
       " '6708070\\t1007267',\n",
       " '10088054\\t1042317',\n",
       " '1195917\\t1042317',\n",
       " '1112006\\t1000557',\n",
       " '1187350\\t1294511',\n",
       " '1116694\\t1327092',\n",
       " '6793225\\t1042317',\n",
       " '1079959\\t1000557']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ANSWER 1 (1 PT)\n",
    "# Print the first 10 records from rawDataRDD\n",
    "artist_allias_rdd.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['06Crazy Life',\n",
       " 'Pang Nakarin',\n",
       " 'Terfel, Bartoli- Mozart: Don',\n",
       " 'The Flaming Sidebur',\n",
       " 'Bodenstandig 3000',\n",
       " 'Jota Quest e Ivete Sangalo',\n",
       " 'Toto_XX (1977',\n",
       " 'U.S Bombs -',\n",
       " 'artist formaly know as Mat',\n",
       " 'Kassierer - Musik für beide Ohren']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ANSWER 2 (1 PT)\n",
    "# Apply parseArtistIdNamePair to rawArtistRDD and print the first 10 records, showing only artist names\n",
    "\n",
    "def parseArtistIdNamePair(singlePair):\n",
    "   splitPair = singlePair.rsplit('\\t')\n",
    "   # we should have two items in the list - id and name of the artist.\n",
    "   if len(splitPair) != 2:\n",
    "       #print singlePair\n",
    "       return []\n",
    "   else:\n",
    "       try:\n",
    "           return [(int(splitPair[0]), splitPair[1])]\n",
    "       except:\n",
    "           return []\n",
    "\n",
    "\n",
    "# do the flatmapping to the RDD using the function and collect, then print the values\n",
    "artistByID = dict(rawArtistRDD.flatMap(lambda x: parseArtistIdNamePair(x)).collect())\n",
    "artist_vals = artistByID.values()\n",
    "list(artist_vals)[:10]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Rating(user=1000002, product=1000014, rating=42.0),\n",
       " Rating(user=1000002, product=1000088, rating=157.0),\n",
       " Rating(user=1000002, product=1000139, rating=56.0),\n",
       " Rating(user=1000002, product=1000140, rating=95.0),\n",
       " Rating(user=1000002, product=1000210, rating=23.0)]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ANSWER 3 (1 PT)\n",
    "# Print the first 5 records from trainData\n",
    "trainData.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Café Del Mar', 'Eric Clapton', 'Eurythmics']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ANSWER 4 (1 PT)\n",
    "# Print the artist listens for testUserID = 1000002\n",
    "[x for x in artistsForUser if x is not None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Eric Clapton', 'Dark Tranquillity', '植松伸夫', 'Scorpions', 'Enigma', 'Gary Jules', 'Eurythmics', 'Elvis Costello', 'Saliva', 'Nena']\n"
     ]
    }
   ],
   "source": [
    "# ANSWER 5 (2 PTS)\n",
    "# Make 10 recommendations for testUserID = 1000002\n",
    "num_recomm = 600 # this filters down to 10 after filtering Nones\n",
    "recommendationsForUser = map(lambda observation: artistByID.get(observation.product), model.call(\"recommendProducts\", testUserID, num_recomm))\n",
    "\n",
    "rank10_guess = [x for x in recommendationsForUser if x is not None]\n",
    "print(rank10_guess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Eric Clapton', 'Dark Tranquillity', 'Scorpions', 'Enigma', 'Eurythmics', '植松伸夫', 'Gary Jules', 'Hypocrisy', 'Elvis Costello', 'Nena']\n"
     ]
    }
   ],
   "source": [
    "# ANSWER 6 (2 PTS)\n",
    "# Using the rank 20 model, make 10 recommendations for testUserID = 1000002\n",
    "recommendationsForUser_rank20 = map(lambda observation: artistByID.get(observation.product), m2.call(\"recommendProducts\", testUserID, num_recomm))\n",
    "\n",
    "rank20_guess = [x for x in recommendationsForUser_rank20 if x is not None][:10]\n",
    "print(rank20_guess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank10 Correct: [0, 6]\n",
      "Rank20 Correct: [0, 4]\n"
     ]
    }
   ],
   "source": [
    "# ANSWER 7 (2 PTS)\n",
    "# How does the rank 10 model seem to perform versus the rank 20 model?\n",
    "# The contents of artistsForUser may help answer the question.\n",
    "\n",
    "true = [x for x in artistsForUser if x is not None]\n",
    "\n",
    "# check how many are in for rank 10\n",
    "print('Rank10 Correct:', [rank10_guess.index(x) for x in rank10_guess if x in true])\n",
    "print('Rank20 Correct:', [rank20_guess.index(x) for x in rank20_guess if x in true])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Café Del Mar', 'Eric Clapton', 'Eurythmics']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The rank 20 model does a better job at prioritizing *Eurythmics* which is a true like for the user. Both models did a good job of placing Eric Clapton as the first ranked option. Other than that, there does not appear to be a major difference. In this way, it may be okay to go with the smaller, Rank10 model. Or at least most of the information is contained in the first 10 ranks compared to the second 10 in the 20 Rank model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DS7200 Spark 3.3",
   "language": "python",
   "name": "ds5110_spark3.3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
